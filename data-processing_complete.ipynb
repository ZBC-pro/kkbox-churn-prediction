{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b493838b-49a5-4902-a47a-ae64b2a77463",
   "metadata": {},
   "source": [
    "对数据集的分区，该数据集通常太大，无法放入内存。最快的过程：  \n",
    "使用散列功能将客户ID映射到分区。  \n",
    "计算整数散列，然后除以分区数  \n",
    "按分区对数据框架进行分组，并将每个分区写入适当的目录和文件  \n",
    "对于无法全部放入内存的大文件，请通过分块读取，并通过分区功能发送每个块  \n",
    "现在，我们可以在单个分区上开发一个自动化的特征工程管道。  \n",
    "开发管道后，我们可以使用Spark或Dask等框架通过管道并行运行分区。这将加快整体特征工程过程，并允许我们扩展到更大的数据集。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b7acacd-5013-4363-9382-8d5c5beed322",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import hashlib\n",
    "\n",
    "# 倒入ipython的交互模块、输出显示方式，比如可以一次性输出所有打印，不用print\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "# 显示每一行的结果，一般都是只显示最后一行，而\"all\"是每一行都显示\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# 分块并行处理数据\n",
    "N_PARTITIONS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ee18c8-1335-4cba-a2fe-f6b70295b5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个 customer_id（字符串）进行哈希处理，生成一个 16进制整数\n",
    "# 输出一个唯一且不可逆的整数值，便于后续分区或其他用途\n",
    "def id_to_hash(customer_id):\n",
    "    \"\"\"Return a 16-bit integer hash of a customer id string\"\"\"\n",
    "    # hashlib 是 Python 标准库中的一个模块，用于实现各种哈希算法（如 MD5、SHA256 等）。\n",
    "    # 将输入的 customer_id 转换为 UTF-8 编码的字节串\n",
    "    # 使用 MD5 哈希算法 对字节串生成哈希值\n",
    "    # 哈希值的固定长度特性适合快速比较和查找。\n",
    "    return int(hashlib.md5(customer_id.encode('utf-8')).hexdigest(), 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8838db9-77ab-45ab-b67a-3da2dd87b65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=     1   0     NaN   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0              11                20110911  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/members_v3.csv', nrows = 1)\n",
    "members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "603370f9-4157-4486-8ed9-a8281b3258bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20150930</td>\n",
       "      <td>20151101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  YyO+tlZtAXYXoZhNr3Vg3+dfVQvrBVGO8j1mfqe4ZHc=                 41   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              129                 129              1   \n",
       "\n",
       "   transaction_date  membership_expire_date  is_cancel  \n",
       "0          20150930                20151101          0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/transactions.csv', nrows = 1)\n",
    "transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88a7c916-f188-4e21-b2d3-d1d03dd57f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rxIP2f2aN0rYNp+toI0Obt/N/FYQX8hcO1fTmmy2h34=</td>\n",
       "      <td>20150513</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>280.335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno      date  num_25  num_50  \\\n",
       "0  rxIP2f2aN0rYNp+toI0Obt/N/FYQX8hcO1fTmmy2h34=  20150513       0       0   \n",
       "\n",
       "   num_75  num_985  num_100  num_unq  total_secs  \n",
       "0       0        0        1        1     280.335  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/user_logs.csv', nrows = 1)\n",
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2ba7554-8986-497a-8dad-da273f12701c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn\n",
       "0  waLDQMmcOu2jLDaV1ddDkgCrB/jl6sD66Xzs0Vqax1Y=         1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/train.csv', nrows = 1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f4f7a7ae-ccb2-4a12-bd91-6b1c3cb77210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn\n",
       "0  4n+fXlyJvfQnTeKXTWT507Ll4JVYGrOC8LHCfwBmPE4=         0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/sample_submission_v2/churn_comp_refresh/sample_submission_v2.csv', nrows = 1)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "54c4867f-fe9b-4b9b-aeac-484cb1540697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "209512247756457468966515739358104959027"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将msno列进行哈希处理\n",
    "\n",
    "# 获取了 members DataFrame 中第一个用户的 msno 值。\n",
    "id_to_hash(members.loc[0, 'msno'])\n",
    "# 计算了该 msno 值的哈希值，根据哈希值和分区数量，确定了该 msno 对应的数据应该被分配到哪个分区。\n",
    "id_to_hash(members.loc[0, 'msno']) % N_PARTITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34483620-a1ed-4a05-98e9-99b2eaae42df",
   "metadata": {},
   "source": [
    "id_to_hash(members.loc[0, 'msno'])： 这行代码首先提取了 members DataFrame 中第一行 (索引为 0) 中 msno 列的值，然后将该值传入了自定义的哈希函数 id_to_hash 进行计算， 生成了一个巨大的整数 209512247756457468966515739358104959027 (哈希值)\n",
    "  \n",
    "id_to_hash(members.loc[0, 'msno']) % N_PARTITIONS： 然后对这个哈希值取模 N_PARTITIONS ( 假设 N_PARTITIONS = 1000)， 得到结果 27 。  \n",
    "  \n",
    "这里的 N_PARTITIONS 代表数据需要被划分成多少个分区。  \n",
    "\n",
    "% 是取模运算符，用来确定特定数据应分配到哪个分区。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "758f54af-06d8-4eee-9d5d-545df13dd200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311407269432611323870693642675616983728"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 交易表哈希处理\n",
    "id_to_hash(transactions.loc[0, 'msno'])\n",
    "id_to_hash(transactions.loc[0, 'msno']) % N_PARTITIONS  # 取模划分区"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66036f4-3983-4830-b780-32985c4e8143",
   "metadata": {},
   "source": [
    "以下代码创建N_PARTITIONS空目录。每个目录中的文件将命名完全相同，因此目录名称可用于区分分区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "324918e5-7dfc-4dad-a582-ead8f2db4250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "base_dir = 'data/partitions/'\n",
    "\n",
    "if not os.path.exists(base_dir + 'p999'):\n",
    "    # 为每个分区创建文件目录\n",
    "    for i in range(N_PARTITIONS):\n",
    "        # 如果目录已经存在，exist_ok=False，会抛出异常\n",
    "        os.makedirs(base_dir + f'p{i}', exist_ok=False)\n",
    "    \n",
    "len(os.listdir(base_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e78b28-74f8-4fdb-82c1-b25234f38dc3",
   "metadata": {},
   "source": [
    "创建文件\n",
    "\n",
    "每个分区都有5个csv文件。\n",
    "\n",
    "transactions.csv  \n",
    "train.csv  \n",
    "test.csv  \n",
    "members.csv  \n",
    "logs.csv  \n",
    "以下代码为每个N_PARTITION分区中的五个文件中的每个文件写入标头。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "29ffede3-0355-4c7e-a2ce-d924c36a024b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'msno,payment_method_id,payment_plan_days,plan_list_price,actual_amount_paid,is_auto_renew,transaction_date,membership_expire_date,is_cancel'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 配置 IPython 交互式环境，使其仅显示最后一个表达式的结果。\n",
    "# 从 transactions DataFrame 获取所有列名，并以逗号分隔的形式生成一个字符串。\n",
    "InteractiveShell.ast_node_interactivity = 'last_expr'  # 仅显示最后一个 有效表达式 的输出\n",
    "','.join(list(transactions.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7e688e-c23b-4a4d-ab7c-6ff601a0de4e",
   "metadata": {},
   "source": [
    "创建分区目录: 根据 N_PARTITIONS 的值，在 ../data/partitions/ 目录下创建多个子目录 (p0, p1, ... p999)，用于数据分区。  \n",
    "\n",
    "创建空白 CSV 文件： 在每个分区目录下，创建五个指定名称的空白 CSV 文件 (transactions.csv, train.csv, test.csv, members.csv, logs.csv)。  \n",
    " \n",
    "写入表头： 将之前读取的 DataFrame 的列名写入相应的 CSV 文件，作为表头。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abb55502-9f59-432a-b6f9-146186cb69da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_blank_partitions():\n",
    "    \"\"\"Create blank files in each partition and write the file header\"\"\"\n",
    "    # 为每个分区创建带有头文件的五个csv文件，1000个文件\n",
    "    for i in range(N_PARTITIONS):\n",
    "        directory = base_dir + f'p{i}/'\n",
    "        # 创建五个csv文件\n",
    "        for file in ['transactions.csv', 'train.csv', 'test.csv', 'members.csv', 'logs.csv']:\n",
    "            # 文件头写入第一行\n",
    "            with open(directory + file, 'w') as f:\n",
    "                if file == 'transactions.csv':\n",
    "                    f.write(','.join(list(transactions.columns)))\n",
    "                elif file == 'train.csv':\n",
    "                    f.write(','.join(list(train.columns)))\n",
    "                elif file == 'test.csv':\n",
    "                    f.write(','.join(list(train.columns)))\n",
    "                elif file == 'members.csv':\n",
    "                    f.write(','.join(list(members.columns)))\n",
    "                elif file == 'logs.csv':\n",
    "                    f.write(','.join(list(logs.columns)))\n",
    "                    \n",
    "    return directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf7ef818-51f0-4985-82de-c41fb4d53bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'members.csv', 'logs.csv', 'train.csv', 'transactions.csv']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = create_blank_partitions()\n",
    "# 返回最后一个创建的p999问价夹中的内容\n",
    "os.listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23399fa8-dece-4ed6-82ef-6729736f176e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [msno, city, bd, gender, registered_via, registration_init_time]\n",
       "Index: []"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 当需要写入数据时，我们将使用附加(a)选项打开现有文件，并添加到任何文件中。此时，每个文件都只有一个标题。\n",
    "pd.read_csv(directory + 'members.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262303e2-5fad-4486-8d0c-21ffb40cd2f7",
   "metadata": {},
   "source": [
    "### 向csv文件内写入数据，写一行的例子  \n",
    " \n",
    "对于每个文件，将数据写入分区的一个选项是一次迭代一个行。处理行的过程是：  \n",
    "\n",
    "通过散列将客户ID转换为整数  \n",
    "通过模数除以分区数将整数转换为分区数  \n",
    "将行附加到正确的分区目录和文件  \n",
    "让我们看看这在单行上是如何工作的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dbde3102-96ae-4348-a609-88bb59e682d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一行一行的方式迭代df\n",
    "# i表示行号，row表示该行\n",
    "for i, row in members.iterrows():\n",
    "    # 通过对id进行散列查找分区\n",
    "    partition = id_to_hash(row['msno']) % N_PARTITIONS\n",
    "    # 'a'：打开文件进行追加。如果文件不存在，会创建新文件。如果文件已经存在，新的内容会被添加到文件的末尾，而不会覆盖原有内容\n",
    "    with open(base_dir + f'p{partition}/members.csv', 'a') as f:\n",
    "        # 写一个换行符，然后写信息\n",
    "        f.write('\\n')\n",
    "        # 以逗号为分隔符写入每个新的csv文件中，遍历行\n",
    "        f.write(','.join([str(x) for x in row.values]))\n",
    "    if i > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a061457-bc20-47a1-9a58-24e5dcf34859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>20110911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  Rb9UwLQTrxzBVwCB6+bCcSQWZ9JiNLC9dXtM1oEsZA8=     1   0     NaN   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0              11                20110911  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/members.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e63308a-5262-4cfe-ad41-25ec980d9715",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '。' (U+3002) (2725757882.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[17], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    一切看起来在第一次尝试时都进展顺利。然而，我们可能想问一下，使用 iterrows 逐行遍历数据集是否是最快的选择。\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '。' (U+3002)\n"
     ]
    }
   ],
   "source": [
    "一切看起来在第一次尝试时都进展顺利。然而，我们可能想问一下，使用 iterrows 逐行遍历数据集是否是最快的选择。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5195119-3ab1-4fc5-bcb3-a546453f7228",
   "metadata": {},
   "source": [
    "不同方法的性能\n",
    "\n",
    "有许多不同的选项来处理将数据写入到正确的分区。为了找出哪种方法最好，我们将尝试 4 种方法：\n",
    "\n",
    "df.iterrows()： 逐行遍历 DataFrame，每一行表示为一个 Series 对象。\n",
    "\n",
    "df.itertuples()： 逐行遍历 DataFrame，每一行表示为一个元组对象。\n",
    "\n",
    "df.apply()： 逐行遍历 DataFrame，每次使用 apply 函数。\n",
    "\n",
    "groupby(partition) 并使用 to_csv() 保存每个分组： 逐个分区地遍历 DataFrame。\n",
    "\n",
    "这四种方法具有不同的适用性和性能特征（请参阅这个 Stack Overflow 回答）。 要找出哪个最快的方法，最好的方式是都尝试一下。 这并不意味着代表所有使用情况，因此你的具体结果可能会有所不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9de0986b-c152-41b6-b13c-5b362f494e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27ef3df2-3537-4b91-ab89-b526e991d61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6769473, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/members_v3.csv')\n",
    "members.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7bb0ab-9e86-468b-b2e1-c7a3ba3e174a",
   "metadata": {},
   "source": [
    "### Iterrows 方法\n",
    "\n",
    "要尝试的第一个实现是 iterrows。这种方法相当慢，因为 Pandas 在迭代之前会将每一行打包成一个 Pandas Series 对象。然而，它允许我们使用常规的定位方式访问每个值。\n",
    "\n",
    "Iterrows: 这是 Pandas DataFrame 的一个方法，用于逐行迭代 DataFrame。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57a1e9a3-beb9-4284-a543-bedf51f5de84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6769472 lines took 575 seconds using iterrows.\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "# 遍历 members.csv 中的行列内容\n",
    "for i, row in members.iterrows():\n",
    "    # 通过对id进行散列查找分区号\n",
    "    partition = id_to_hash(row['msno']) % N_PARTITIONS\n",
    "    \n",
    "    # 打开文件将 members.csv 中的信息追加到各个分区的 csv 文件中\n",
    "    with open(base_dir + f'p{partition}/members.csv', 'a') as f:\n",
    "        # Write a new line and then data\n",
    "        f.write('\\n')\n",
    "        f.write(','.join([str(x) for x in row.values]))\n",
    "\n",
    "    # 每一万条信息打印一次\n",
    "    if i % 10000 == 0:\n",
    "        # 打印处理进度，用当前处理到第几行处以总条数，保留两位显示百分比    '\\r'是回车\n",
    "        print(f'{100 * round(i / members.shape[0], 2)}% complete. {round(timer() - start)} seconds elapsed.', end = '\\r')\n",
    "\n",
    "end = timer()\n",
    "print(f'Processing {i} lines took {round(end - start)} seconds using iterrows.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22b210b2-518f-4e19-a227-b60991bc1e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+zMKqjvsTvD7O0Fvntk3VXe4ovwvD4KYk6PJZ92Ky60=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20161227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3p2AY1tZAYa4LFcs0/plkuPv2hY9smh/xgcbKjtU9Dc=</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>20141109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BO0XUBzHeItkHI3N5g4uL08Ld1T/ZW/8GrbjBmT4s3w=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20161228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qy7PNK2EE4+x6xeIdqjFVw5FlmxnFKylv6LKqqGbSo4=</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>20170113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c36721uHBQyhoVko21J9rR44Fex2ul72a74k0M7IkiQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  +zMKqjvsTvD7O0Fvntk3VXe4ovwvD4KYk6PJZ92Ky60=     1   0     NaN   \n",
       "1  3p2AY1tZAYa4LFcs0/plkuPv2hY9smh/xgcbKjtU9Dc=     5  26    male   \n",
       "2  BO0XUBzHeItkHI3N5g4uL08Ld1T/ZW/8GrbjBmT4s3w=     1   0     NaN   \n",
       "3  qy7PNK2EE4+x6xeIdqjFVw5FlmxnFKylv6LKqqGbSo4=     1  23  female   \n",
       "4  c36721uHBQyhoVko21J9rR44Fex2ul72a74k0M7IkiQ=     1   0     NaN   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0               9                20161227  \n",
       "1               3                20141109  \n",
       "2               7                20161228  \n",
       "3               4                20170113  \n",
       "4               4                20170121  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/members.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4f593-068e-4a43-aeef-fd7eab799bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "这种方法有效，但速度相当慢。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab552b-008b-404a-be3b-001879862f92",
   "metadata": {},
   "source": [
    "### Itertuples 方法\n",
    "\n",
    "itertuples 应该比 iterrows 快，因为 Pandas 将每一行打包为一个元组而不是一个 Series 对象。   \n",
    "这种权衡是，我们需要在访问 Series 的元素时小心，因为我们不能通过名称来引用它们。  \n",
    "例如，为了确保我们正在哈希处理客户 ID (msno)，我们需要获取元组的第二个元素。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f57df0-f620-4c41-886b-362f6f1c6fb2",
   "metadata": {},
   "source": [
    "Itertuples: 这是 Pandas DataFrame 的一个方法，用于逐行迭代 DataFrame。\n",
    "\n",
    "元组 (tuple): Python 中的一种数据结构，类似于列表，但是元组是不可变的，并且通常用于表示固定的数据项。\n",
    "\n",
    "Series 对象： 这是 Pandas 中的一种数据结构，类似于一维数组，并且带有索引。\n",
    "\n",
    "权衡 (tradeoff): 这里指的是，使用 itertuples 方法获得性能提升的同时，也带来了一些新的挑战。\n",
    "\n",
    "通过名称来引用它们 (refer to them by name): 指的是使用列名来访问 Series 中的数据（例如 row['msno']）。\n",
    "\n",
    "元组的第二个元素: 由于元组不能通过列名来访问，因此需要使用基于位置的索引（例如row[1]）来访问指定列的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fa346d8-ad59-4557-9580-bb46da3b5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = create_blank_partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f00e104-ed2c-41b0-b67b-f707431fcc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6769472 lines took 725 seconds using itertuples.\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "for i, tup in enumerate(members.itertuples()):\n",
    "    \n",
    "    # 计算分区 id\n",
    "    partition = id_to_hash(tup[1]) % N_PARTITIONS\n",
    "    \n",
    "    # Open file for appending\n",
    "    with open(base_dir + f'p{partition}/members.csv', 'a') as f:\n",
    "        # Write a new line and then data\n",
    "        f.write('\\n')\n",
    "        f.write(','.join([str(x) for x in tup[1:]]))\n",
    "        \n",
    "    if i % 10000 == 0:\n",
    "        print(f'{100 * round(i / members.shape[0], 2)}% complete. {round(timer() - start)} seconds elapsed.', end = '\\r')\n",
    "\n",
    "end = timer()\n",
    "print(f'Processing {i} lines took {round(end - start)} seconds using itertuples.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e68547e-777f-45f3-9d7c-32eb692ba1be",
   "metadata": {},
   "source": [
    "iterrows() 返回的是 Series，每一行的数据被包装成一个 Pandas Series 对象，索引是列名，值是对应列的数据。  \n",
    "itertuples() 返回的是一整行的数据，但以 命名元组（namedtuple） 的形式，既可以通过字段名（列名）访问，也可以通过索引访问。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2002b9c2-a46c-4904-a865-a6c4588d276f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+zMKqjvsTvD7O0Fvntk3VXe4ovwvD4KYk6PJZ92Ky60=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20161227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3p2AY1tZAYa4LFcs0/plkuPv2hY9smh/xgcbKjtU9Dc=</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>20141109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BO0XUBzHeItkHI3N5g4uL08Ld1T/ZW/8GrbjBmT4s3w=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20161228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qy7PNK2EE4+x6xeIdqjFVw5FlmxnFKylv6LKqqGbSo4=</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>20170113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c36721uHBQyhoVko21J9rR44Fex2ul72a74k0M7IkiQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  +zMKqjvsTvD7O0Fvntk3VXe4ovwvD4KYk6PJZ92Ky60=     1   0     NaN   \n",
       "1  3p2AY1tZAYa4LFcs0/plkuPv2hY9smh/xgcbKjtU9Dc=     5  26    male   \n",
       "2  BO0XUBzHeItkHI3N5g4uL08Ld1T/ZW/8GrbjBmT4s3w=     1   0     NaN   \n",
       "3  qy7PNK2EE4+x6xeIdqjFVw5FlmxnFKylv6LKqqGbSo4=     1  23  female   \n",
       "4  c36721uHBQyhoVko21J9rR44Fex2ul72a74k0M7IkiQ=     1   0     NaN   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0               9                20161227  \n",
       "1               3                20141109  \n",
       "2               7                20161228  \n",
       "3               4                20170113  \n",
       "4               4                20170121  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/members.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736f2fbc-90c8-41ad-bdb6-8b1381eeff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "这种方法快得多，因为 Pandas 不必将每一行转换为一个 Series 对象，而 Series 对象比元组有更多的开销。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48186fe9-14f7-434d-9ce2-0fc68a55c920",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = create_blank_partitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a872e2c-354c-427b-be48-e927d30691d4",
   "metadata": {},
   "source": [
    "### Apply 方法\n",
    "\n",
    "另一个选项是使用 apply 方法来处理行。   \n",
    "为了使用 apply， 我们需要编写一个小函数，该函数保存当前行，然后使用 axis = 1 将 apply 函数调用到 DataFrame 上，这会将每一行发送到函数。   \n",
    "这也会将每一行作为 Series 发送到函数，但在实践中它看起来比 iterrows 快得多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0b9a8658-5029-4af7-9ca2-dcc6150d604e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_row(row, name):\n",
    "    # Find the partition number by hashing the id\n",
    "    partition = id_to_hash(row['msno']) % N_PARTITIONS\n",
    "    \n",
    "    # Open file for appending\n",
    "    with open(base_dir + f'p{partition}/{name}.csv', 'a') as f:\n",
    "        # Write a new line and then data\n",
    "        f.write('\\n')\n",
    "        f.write(','.join([str(x) for x in row.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50831301-2fc1-4142-8a88-cf4b0a6feada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 6769473/6769473 [09:56<00:00, 11356.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6769473 rows took 596 seconds using apply.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "start = timer()\n",
    "# apply 应用函数，将csv中的每一行作用于函数，速度适中，有良好的封装性\n",
    "members.progress_apply(save_row, axis = 1, name = 'members')\n",
    "end = timer()\n",
    "\n",
    "print(f'Processing {members.shape[0]} rows took {round(end - start)} seconds using apply.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31c0a524-e204-489d-902f-842b986153b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>+zMKqjvsTvD7O0Fvntk3VXe4ovwvD4KYk6PJZ92Ky60=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>20161227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3p2AY1tZAYa4LFcs0/plkuPv2hY9smh/xgcbKjtU9Dc=</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>20141109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BO0XUBzHeItkHI3N5g4uL08Ld1T/ZW/8GrbjBmT4s3w=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>20161228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qy7PNK2EE4+x6xeIdqjFVw5FlmxnFKylv6LKqqGbSo4=</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>female</td>\n",
       "      <td>4</td>\n",
       "      <td>20170113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c36721uHBQyhoVko21J9rR44Fex2ul72a74k0M7IkiQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  +zMKqjvsTvD7O0Fvntk3VXe4ovwvD4KYk6PJZ92Ky60=     1   0     NaN   \n",
       "1  3p2AY1tZAYa4LFcs0/plkuPv2hY9smh/xgcbKjtU9Dc=     5  26    male   \n",
       "2  BO0XUBzHeItkHI3N5g4uL08Ld1T/ZW/8GrbjBmT4s3w=     1   0     NaN   \n",
       "3  qy7PNK2EE4+x6xeIdqjFVw5FlmxnFKylv6LKqqGbSo4=     1  23  female   \n",
       "4  c36721uHBQyhoVko21J9rR44Fex2ul72a74k0M7IkiQ=     1   0     NaN   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0               9                20161227  \n",
       "1               3                20141109  \n",
       "2               7                20161228  \n",
       "3               4                20170113  \n",
       "4               4                20170121  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/members.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2eb00f-f07d-4a4f-a1c4-ede14cb5c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "所以 apply 比 iterrows 快，但比 itertuples 慢（至少在这种情况下）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21a40a3-64ab-465f-b8cd-e32988d0f0f2",
   "metadata": {},
   "source": [
    "## Groupby 方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5389e5-48ea-4e0e-bf7d-849f6831a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = create_blank_partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08f55fe-e124-43e4-8906-d9be2756c75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Groupby\n",
    "\n",
    "我们将尝试的最后一个选项是在一次操作中，将所有客户 ID 转换为分区编号后，按分区对数据进行分组。  \n",
    "\n",
    "一次性使用哈希函数计算分区。  \n",
    "\n",
    "按分区进行分组。  \n",
    "\n",
    "将分组后的 DataFrame 写入到正确的分区目录和文件中。  \n",
    "\n",
    "为了找出将所有客户 ID 转换为整数的最快方法，我们可以比较 map 和 apply。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1be4b4-f1f1-4175-be17-e5dea6a2d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "Groupby: 指的是 Pandas DataFrame 中的 groupby() 方法，用于将数据按照某些列的值进行分组。  \n",
    "\n",
    "Partition: 分区，指将数据划分成更小的部分。  \n",
    "\n",
    "Hashing function: 哈希函数，一种用于将数据映射为固定长度哈希值的函数。  \n",
    "\n",
    "map： pandas中的map函数，可以高效的映射转换。  \n",
    "\n",
    "apply pandas中的apply函数， 可以基于行或者列进行处理，比较灵活，但是效率不如向量化操作。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "736ed16c-f463-49ad-9569-3b5e3b2c865a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07 s ± 20.3 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 3\n",
    "members['msno'].map(id_to_hash) % 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3833c72f-51d2-4f1c-af27-8d8ae2ae3de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit 是 Jupyter Notebook 的一个魔法命令，用于测量代码块的运行时间。\n",
    "\t参数：\n",
    "\t-n 1 表示每次只运行一次（loop count）。\n",
    "\t-r 3 表示重复测试 3 次，然后取平均值和标准差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbb85b0b-baa2-49f1-beb0-b5ed6f95a290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.96 s ± 77.5 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 3\n",
    "members['msno'].apply(id_to_hash) % 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dbec5b-bfbd-4a2d-ba3a-4e4ae7473922",
   "metadata": {},
   "source": [
    "members['msno'].map(id_to_hash) % 1000：\n",
    "\n",
    "members['msno']: 选取 members DataFrame 中列名为 msno 的数据，返回一个 Series 对象。\n",
    "\n",
    ".map(id_to_hash): 对 msno 列的每个元素执行 id_to_hash 函数。\n",
    "\n",
    "% 1000: 对 map 返回的哈希值进行取模操作，除以 1000 得到分区索引。\n",
    "\n",
    "作用： 这行代码使用 map 方法，对 members DataFrame 中所有 msno 列的值进行哈希运算，并取模，从而获得分区索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2e6192-768a-4418-9aa2-2ec7299b238f",
   "metadata": {},
   "source": [
    "members['msno'].apply(id_to_hash) % 1000：\n",
    "\n",
    "members['msno']: 选取 members DataFrame 中列名为 msno 的数据，返回一个 Series 对象。\n",
    "\n",
    ".apply(id_to_hash): 对 msno 列的每个元素执行 id_to_hash 函数。\n",
    "\n",
    "% 1000: 对 apply 返回的哈希值进行取模操作，除以 1000 得到分区索引。\n",
    "\n",
    "作用： 这行代码使用 apply 方法，对 members DataFrame 中所有 msno 列的值进行哈希运算，并取模，从而获得分区索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff880cad-bfdc-45c9-b8f7-fa75dd3d94de",
   "metadata": {},
   "source": [
    "*看起来 apply 稍微快一些*，  \n",
    "我们将一次性将所有客户 ID 转换为分区，因此这不是一个很大的时间成本。  \n",
    "在我们继续之前，我们应该确保哈希和转换为分区操作创建的分区大小接近。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1094b6f1-5939-46e5-a71a-f702c9174fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "partition\n",
       "689    7027\n",
       "842    7012\n",
       "844    6992\n",
       "660    6986\n",
       "91     6983\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members['partition'] = members['msno'].apply(id_to_hash) % 1000\n",
    "members['partition'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d8c9b9c3-44bf-4858-bb4b-c0f388b74437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean     6769.473000\n",
       "std        81.213231\n",
       "min      6494.000000\n",
       "25%      6716.000000\n",
       "50%      6773.000000\n",
       "75%      6825.000000\n",
       "max      7027.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "members['partition'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58587893-faa0-4257-94cf-3da6b58fcc98",
   "metadata": {},
   "source": [
    "看起来每个分区中的成员数量相当恒定。我们可以检查另一个数据集来确保这一点。  \n",
    "最大的文件中有7027个用户，最小的有6494个用户"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a92e344-a6db-4b83-9516-bd808b2ebad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1000.000000\n",
       "mean     21547.746000\n",
       "std        618.434304\n",
       "min      19572.000000\n",
       "25%      21125.750000\n",
       "50%      21528.500000\n",
       "75%      21962.750000\n",
       "max      23714.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/transactions.csv')\n",
    "transactions['partition'] = transactions['msno'].apply(id_to_hash) % 1000\n",
    "transactions['partition'].value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddac525-7749-43cf-8e1d-2cf634b0fdd0",
   "metadata": {},
   "source": [
    "接下来的单元格（cell）将以分组（groupby）的方式运行，来对数据进行分区。  \n",
    "需要注意的最大事项是，确保我们每次都以附加模式（使用 open with a）写入文件。  \n",
    "当我们使用 to_csv 写入 CSV 文件时，我们可以传入一个已经打开的文件。  \n",
    "我们也不写入表头，因为我们已经在每个文件中创建了表头，并且不写入索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27d9a3aa-f210-4644-b7c8-4afd658da00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 6769473 rows took 12 seconds using groupby.\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "members['partition'] = members['msno'].apply(id_to_hash) % N_PARTITIONS\n",
    "\n",
    "# Iteration through grouped partitions\n",
    "# 通过 partition 直接进行分组，将分组后的 grouped 行直接写入csv文件中\n",
    "for partition, grouped in members.groupby('partition'):\n",
    "\n",
    "    # 删除分区号\n",
    "    grouped = grouped.drop(columns = 'partition')\n",
    "    # Open file for appending\n",
    "    # 追加组中数据\n",
    "    with open(base_dir + f'p{partition}/members.csv', 'a') as f:\n",
    "        f.write('\\n')\n",
    "        grouped.to_csv(f, header = False, index = False)\n",
    "        \n",
    "end = timer()\n",
    "print(f'Processing {members.shape[0]} rows took {round(end - start)} seconds using groupby.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7aaf26e-e438-4b08-a5dd-ef3ff10844a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bpIibSSY6wymQbGaQOR9q6dcWKg7lUfw3Y+LttzAQNQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HZwqy9brMyBDuFVpXlAqli8yoAixLc1rA0ExAZYZR50=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>20130220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kW0/xDZUihRKFMa3ti+vq3fF/O2li5aYpY+szvzg0ko=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20130227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yCUq5TNkbcJF0inE45ICYI//gZ+FzPmwSZWmFie4nk8=</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20130305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VsM62mNuBRPH2YZSZKaRlD0IQsqoJa55aKxukV84oY4=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>20150213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  bpIibSSY6wymQbGaQOR9q6dcWKg7lUfw3Y+LttzAQNQ=     1   0     NaN   \n",
       "1  HZwqy9brMyBDuFVpXlAqli8yoAixLc1rA0ExAZYZR50=     1   0    male   \n",
       "2  kW0/xDZUihRKFMa3ti+vq3fF/O2li5aYpY+szvzg0ko=     1   0     NaN   \n",
       "3  yCUq5TNkbcJF0inE45ICYI//gZ+FzPmwSZWmFie4nk8=     6  31  female   \n",
       "4  VsM62mNuBRPH2YZSZKaRlD0IQsqoJa55aKxukV84oY4=     1   0  female   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0               4                20170104  \n",
       "1               3                20130220  \n",
       "2               3                20130227  \n",
       "3               9                20130305  \n",
       "4               3                20150213  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/members.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd09c17-a134-402b-9da7-426189bff81e",
   "metadata": {},
   "source": [
    "按分组去存储csv文件就是提前将所有的分区号归类然后进行统一保存，相对于前面的iterrows、itertuples、progress_apply，都是一条一条去处理，而groupby是根据分组进行处理，很高效  \n",
    "按分区对数据进行分组的方法是目前最快的方法。我们将把这个方法放入一个函数中，以便用于所有数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ca41c7-ed0f-45e1-81f9-03b0241ed297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bfc8caf-0079-4802-9a29-161fb1da6ae0",
   "metadata": {},
   "source": [
    "可复用的哈希 DataFrame 函数\n",
    "\n",
    "为了使该过程可复用，我们将编写一个函数来为我们完成此操作。  \n",
    "它将接收一个 DataFrame，一个用于保存数据的文件名，以及一个可选的进度参数。该函数将使用哈希模运算（hash-modulo）分区数的方法，将客户 ID (msno) 映射到分区编号，按分区对 DataFrame 进行分组，并将分组后的 DataFrame 写入到相应的目录。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eea88e-4041-4b95-854c-4c5360521844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# members = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/members_v3.csv', nrows = 1)\n",
    "# transactions = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/transactions.csv', nrows = 1)\n",
    "# logs = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/user_logs.csv', nrows = 1)\n",
    "# train = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/train.csv', nrows = 1)\n",
    "# test = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/sample_submission_v2.csv', nrows = 1)\n",
    "\n",
    "# _ = create_blank_partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "386e675a-9737-4910-b18a-88213b692e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bpIibSSY6wymQbGaQOR9q6dcWKg7lUfw3Y+LttzAQNQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HZwqy9brMyBDuFVpXlAqli8yoAixLc1rA0ExAZYZR50=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>20130220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kW0/xDZUihRKFMa3ti+vq3fF/O2li5aYpY+szvzg0ko=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20130227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yCUq5TNkbcJF0inE45ICYI//gZ+FzPmwSZWmFie4nk8=</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20130305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VsM62mNuBRPH2YZSZKaRlD0IQsqoJa55aKxukV84oY4=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>20150213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  bpIibSSY6wymQbGaQOR9q6dcWKg7lUfw3Y+LttzAQNQ=     1   0     NaN   \n",
       "1  HZwqy9brMyBDuFVpXlAqli8yoAixLc1rA0ExAZYZR50=     1   0    male   \n",
       "2  kW0/xDZUihRKFMa3ti+vq3fF/O2li5aYpY+szvzg0ko=     1   0     NaN   \n",
       "3  yCUq5TNkbcJF0inE45ICYI//gZ+FzPmwSZWmFie4nk8=     6  31  female   \n",
       "4  VsM62mNuBRPH2YZSZKaRlD0IQsqoJa55aKxukV84oY4=     1   0  female   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0               4                20170104  \n",
       "1               3                20130220  \n",
       "2               3                20130227  \n",
       "3               9                20130305  \n",
       "4               3                20150213  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/partitions/p999/members.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58ee87e9-57df-42c2-9a40-dc8f9360d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 传入df、需要拆分的csv文件，处理多少行后显示进度信息，默认不显示\n",
    "def partition_by_hashing(df, name, progress = None):\n",
    "    \"\"\"Partition a dataframe into N_PARTITIONS by hashing the id.\n",
    "    \n",
    "    Params\n",
    "    --------\n",
    "        df (pandas dataframe): dataframe for partition. Must have 'msno' column.\n",
    "        name (str): name of dataframe. Used for saving the row data.\n",
    "        progress (int, optional): number of rows to be processed before displaying information.\n",
    "                                  Defaults to None\n",
    "                                  \n",
    "    Returns:\n",
    "    --------\n",
    "        Nothing returned. Dataframe is saved one line at a time as csv files to the N_PARTITIONS \n",
    "    \"\"\"\n",
    "    \"\"\"通过对 id 进行哈希将 DataFrame 划分为 N_PARTITIONS。\n",
    "\n",
    "    参数\n",
    "    --------\n",
    "        df (pandas DataFrame): 需要划分的 DataFrame。必须包含 'msno' 列。\n",
    "        name (str): DataFrame 的名称。用于保存行数据。\n",
    "        progress (int, 可选): 每处理多少行后显示进度信息。默认为 None。\n",
    "        \n",
    "    返回\n",
    "    --------\n",
    "        无返回值。DataFrame 会一行一行地保存为 CSV 文件，划分到 N_PARTITIONS 中。\n",
    "\"\"\"\n",
    "    start = timer()\n",
    "    \n",
    "    # Map the customer id to a partition number\n",
    "    df['partition'] = df['msno'].apply(id_to_hash) % N_PARTITIONS\n",
    "    \n",
    "    # Iterate through one row at a time\n",
    "    for partition, grouped in df.groupby('partition'):\n",
    "        \n",
    "        # Don't need to save the partition column\n",
    "        grouped = grouped.drop(columns = 'partition')\n",
    "        \n",
    "        # Open file for appending\n",
    "        with open(base_dir + f'p{partition}/{name}.csv', 'a') as f:\n",
    "            # Write a new line and then data\n",
    "            f.write('\\n')\n",
    "            grouped.to_csv(f, header = False, index = False)\n",
    "            \n",
    "        # Record progress every `progress` steps\n",
    "        if progress is not None:\n",
    "            if partition % progress == 0:\n",
    "                print(f'{100 * round(partition / N_PARTITIONS, 2)}% complete. {round(timer() - start)} seconds elapsed.', end = '\\r')\n",
    "    \n",
    "    end = timer()\n",
    "    if progress is not None:\n",
    "        print(f'\\n{df.shape[0]} rows processed in {round(end - start)} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8e9e97e7-0f3f-4e78-8070-5a02a9be2572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0% complete. 10 seconds elapsed.nds elapsed..\n",
      "6769473 rows processed in 10 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 直接调用\n",
    "members = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/members_v3.csv')\n",
    "partition_by_hashing(members, name = 'members', progress = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4670ae72-1665-4cc2-8b1e-99ac013af962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>city</th>\n",
       "      <th>bd</th>\n",
       "      <th>gender</th>\n",
       "      <th>registered_via</th>\n",
       "      <th>registration_init_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bpIibSSY6wymQbGaQOR9q6dcWKg7lUfw3Y+LttzAQNQ=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>20170104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HZwqy9brMyBDuFVpXlAqli8yoAixLc1rA0ExAZYZR50=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>3</td>\n",
       "      <td>20130220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kW0/xDZUihRKFMa3ti+vq3fF/O2li5aYpY+szvzg0ko=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>20130227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yCUq5TNkbcJF0inE45ICYI//gZ+FzPmwSZWmFie4nk8=</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>female</td>\n",
       "      <td>9</td>\n",
       "      <td>20130305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VsM62mNuBRPH2YZSZKaRlD0IQsqoJa55aKxukV84oY4=</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>3</td>\n",
       "      <td>20150213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  city  bd  gender  \\\n",
       "0  bpIibSSY6wymQbGaQOR9q6dcWKg7lUfw3Y+LttzAQNQ=     1   0     NaN   \n",
       "1  HZwqy9brMyBDuFVpXlAqli8yoAixLc1rA0ExAZYZR50=     1   0    male   \n",
       "2  kW0/xDZUihRKFMa3ti+vq3fF/O2li5aYpY+szvzg0ko=     1   0     NaN   \n",
       "3  yCUq5TNkbcJF0inE45ICYI//gZ+FzPmwSZWmFie4nk8=     6  31  female   \n",
       "4  VsM62mNuBRPH2YZSZKaRlD0IQsqoJa55aKxukV84oY4=     1   0  female   \n",
       "\n",
       "   registered_via  registration_init_time  \n",
       "0               4                20170104  \n",
       "1               3                20130220  \n",
       "2               3                20130227  \n",
       "3               9                20130305  \n",
       "4               3                20150213  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/members.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb332954-e2c1-46bf-8666-6f25a7f3a123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8de68a49-f673-411d-a310-cc2dc3e65e38",
   "metadata": {},
   "source": [
    "## 训练数据  \n",
    "\n",
    "现在我们可以使用此函数来对训练数据进行分区。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4104e62a-9ee4-41d8-9dd3-a8679aa84dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0% complete. 1 seconds elapsed.onds elapsed..\n",
      "992931 rows processed in 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/train.csv')\n",
    "partition_by_hashing(train, name = 'train', progress = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "531be98f-9526-4940-93d4-181a9d503737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ad9xf2W6ID3zguduv1lKdla80V/iT2cFWbDxIcEMQOs=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nL5mKfbpD9mjLJiIbOa1MsrHXKlmC4Nt5S3ieKtqUq8=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TmSYOz2xCdk5j1hmUP72/FQdkU3kpoqEl9RDc9UBtf8=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NNYVPCEq8Pk2QYIGSBSIiO+XcX/Sqa2TG5+szr4DMuk=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bhzedCaoyawwHOssUE6IXI1BP4I0/4nDC1H6CtXcIK4=</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn\n",
       "0  Ad9xf2W6ID3zguduv1lKdla80V/iT2cFWbDxIcEMQOs=         1\n",
       "1  nL5mKfbpD9mjLJiIbOa1MsrHXKlmC4Nt5S3ieKtqUq8=         1\n",
       "2  TmSYOz2xCdk5j1hmUP72/FQdkU3kpoqEl9RDc9UBtf8=         1\n",
       "3  NNYVPCEq8Pk2QYIGSBSIiO+XcX/Sqa2TG5+szr4DMuk=         1\n",
       "4  bhzedCaoyawwHOssUE6IXI1BP4I0/4nDC1H6CtXcIK4=         1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/train.csv').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df7877f-6792-48f1-a69f-a032d0f36272",
   "metadata": {},
   "source": [
    "### 测试数据\n",
    "\n",
    "函数的优点在于我们可以不断地应用它，只需要改变参数即可！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e77ee7-22bb-4fac-b1da-8e268b301208",
   "metadata": {},
   "source": [
    "Testing Data: 测试数据。  \n",
    "\n",
    "function: 这里指代之前定义的函数，也就是可复用的哈希 DataFrame 函数。  \n",
    "\n",
    "keep applying it: 可以反复应用它。  \n",
    "\n",
    "changing only the arguments: 只需要修改参数，就可以将函数复用到不同数据。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7eb2f6ec-3bee-4ed8-b816-6e4415537b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0% complete. 1 seconds elapsed.onds elapsed..\n",
      "907471 rows processed in 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/sample_submission_v2/churn_comp_refresh/sample_submission_v2.csv')\n",
    "partition_by_hashing(test, name = 'test', progress = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80e3c217-cb28-4411-a52c-5aaeefec6348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>is_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bFTbnI7GC8TZJ2m9dfLF0bkFIEsy/0ERZzmFFekPWpY=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SvdAOG3xp9glZIopNrlnOOiOLHdmnpHfwRGnNUpOrmo=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GG+L3Jv6naoL8JjQYPIem7ISmtoHcMX453sqTSFcl2Q=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OdT/fU9BKs+KrLeypHtoeQut97PBNWlDvjnMCUsJVzY=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f0SvlQcRZBgZbOaoPBkj57xo81+GnlluK1rLyy0PQnc=</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  is_churn\n",
       "0  bFTbnI7GC8TZJ2m9dfLF0bkFIEsy/0ERZzmFFekPWpY=         0\n",
       "1  SvdAOG3xp9glZIopNrlnOOiOLHdmnpHfwRGnNUpOrmo=         0\n",
       "2  GG+L3Jv6naoL8JjQYPIem7ISmtoHcMX453sqTSFcl2Q=         0\n",
       "3  OdT/fU9BKs+KrLeypHtoeQut97PBNWlDvjnMCUsJVzY=         0\n",
       "4  f0SvlQcRZBgZbOaoPBkj57xo81+GnlluK1rLyy0PQnc=         0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/test.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948059e8-2a02-40cf-99eb-ccb50a760529",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40adb693-6caf-4ba8-9274-70a67d40cb54",
   "metadata": {},
   "source": [
    "### 交易数据\n",
    "\n",
    "倒数第二个数据集是客户交易数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d59f0c15-ab61-45ae-96b2-0073ea2f8909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.0% complete. 39 seconds elapsed.onds elapsed..\n",
      "21547746 rows processed in 40 seconds.\n"
     ]
    }
   ],
   "source": [
    "transactions = pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/transactions.csv')\n",
    "partition_by_hashing(transactions, name = 'transactions', progress = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "409fc594-ba69-4f81-91e4-9c3409bb7ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>payment_method_id</th>\n",
       "      <th>payment_plan_days</th>\n",
       "      <th>plan_list_price</th>\n",
       "      <th>actual_amount_paid</th>\n",
       "      <th>is_auto_renew</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>membership_expire_date</th>\n",
       "      <th>is_cancel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>igTF6Ef1Y1chfDlEjV+59Hgp4mfh8ZNVXF/vlv1TvhY=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>20160418</td>\n",
       "      <td>20160518</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wlwPlei0VKJ6AF07YrL04gpbebUPitqtnqa3CnL4tmI=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20150107</td>\n",
       "      <td>20160106</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m40NTt7XHbAVwCI4y6TYH0XBJdPeVVpBUSKT9NXP7xE=</td>\n",
       "      <td>39</td>\n",
       "      <td>30</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>20161231</td>\n",
       "      <td>20170210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wQ8y0ZtCUniH1rWDKyltgP+nfxDV9hAvjcFBa7l9uAU=</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>20160731</td>\n",
       "      <td>20160831</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CZ87lCEDKmbk7EXCy6Kh0zopNJxoEBTfWq9Eq9Az+28=</td>\n",
       "      <td>32</td>\n",
       "      <td>195</td>\n",
       "      <td>894</td>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "      <td>20160726</td>\n",
       "      <td>20170209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno  payment_method_id  \\\n",
       "0  igTF6Ef1Y1chfDlEjV+59Hgp4mfh8ZNVXF/vlv1TvhY=                 41   \n",
       "1  wlwPlei0VKJ6AF07YrL04gpbebUPitqtnqa3CnL4tmI=                 41   \n",
       "2  m40NTt7XHbAVwCI4y6TYH0XBJdPeVVpBUSKT9NXP7xE=                 39   \n",
       "3  wQ8y0ZtCUniH1rWDKyltgP+nfxDV9hAvjcFBa7l9uAU=                 41   \n",
       "4  CZ87lCEDKmbk7EXCy6Kh0zopNJxoEBTfWq9Eq9Az+28=                 32   \n",
       "\n",
       "   payment_plan_days  plan_list_price  actual_amount_paid  is_auto_renew  \\\n",
       "0                 30              129                 129              1   \n",
       "1                 30              149                   0              1   \n",
       "2                 30              149                 149              1   \n",
       "3                 30               99                  99              1   \n",
       "4                195              894                 894              0   \n",
       "\n",
       "   transaction_date  membership_expire_date  is_cancel  \n",
       "0          20160418                20160518          0  \n",
       "1          20150107                20160106          0  \n",
       "2          20161231                20170210          0  \n",
       "3          20160731                20160831          0  \n",
       "4          20160726                20170209          0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/transactions.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9c2cc2-d714-4553-9249-57407a93661e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e24a8bc8-dd93-4f09-a21c-f0abdd4554b9",
   "metadata": {},
   "source": [
    "### 用户日志数据\n",
    "\n",
    "由于文件太大，最终的数据集无法直接传递给函数， 这甚至会阻止我们将整个文件读取到内存中。   \n",
    "相反，我们可以使用 Pandas 一次读取一个数据块（chunk），并将该函数应用于每个数据块。  \n",
    "实际上有两个大小明显不同的日志文件，但我们将对每个文件使用相同的分块方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b28a1701-628b-4abe-858e-30c20c774b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.514081415\n",
      "1.431465728\n"
     ]
    }
   ],
   "source": [
    "print(os.stat('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/user_logs.csv').st_size / 1e9)\n",
    "print(os.stat('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/user_logs_v2/churn_comp_refresh/user_logs_v2.csv').st_size / 1e9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b21fb35-5424-441b-bf5b-766bfc55517d",
   "metadata": {},
   "source": [
    "第二个用户日志可以使用之前的方式进行处理，因为它可以被完整地读取到内存中，但我们仍将继续使用分块方法。  \n",
    "chunksize 指的是一次读取的行数。使用 Pandas 的 read_csv 并指定 chunksize，我们就可以一次迭代一个数据块的文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a1f2d4f0-0383-4d97-b9a0-df470714d089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall time: 49 seconds.\n"
     ]
    }
   ],
   "source": [
    "# 1e6 = 1,000,000 = 100w\n",
    "chunksize = 1e6\n",
    "start = timer()\n",
    "\n",
    "for chunk in pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/user_logs_v2/churn_comp_refresh/user_logs_v2.csv', chunksize = chunksize):\n",
    "    partition_by_hashing(chunk, name = 'logs', progress = None)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f'{i * chunksize} rows processed.', end = '\\r')\n",
    "\n",
    "end = timer()\n",
    "print(f'\\nOverall time: {round(end - start)} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "862f3d43-feac-4383-8d0d-e856800c10c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555bSTll4Rzaz1vBg/VfGfaXKEE8S74EAdKPOCkBqpg=</td>\n",
       "      <td>20170301</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>6306.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KORJwjTctoWENM9oM2Rrl432wxllmC1RvP5p84PUFI8=</td>\n",
       "      <td>20170316</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>34</td>\n",
       "      <td>10718.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>+GdZIQJdsQSeRKyu/GONhgWzK4R8Ufm59RpzwAj4OCE=</td>\n",
       "      <td>20170310</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>4948.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9yZc5dve4sg96RQT1FyTPSmcDWrIVu+qsI7W7oOmFvE=</td>\n",
       "      <td>20170306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>3436.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rq9NMOw9RAbN3qUIG1MUU+vL0lqhAJUAsZiW0dsm/Lg=</td>\n",
       "      <td>20170322</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>67</td>\n",
       "      <td>13534.787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           msno      date  num_25  num_50  \\\n",
       "0  555bSTll4Rzaz1vBg/VfGfaXKEE8S74EAdKPOCkBqpg=  20170301       2       0   \n",
       "1  KORJwjTctoWENM9oM2Rrl432wxllmC1RvP5p84PUFI8=  20170316       6       1   \n",
       "2  +GdZIQJdsQSeRKyu/GONhgWzK4R8Ufm59RpzwAj4OCE=  20170310       5       1   \n",
       "3  9yZc5dve4sg96RQT1FyTPSmcDWrIVu+qsI7W7oOmFvE=  20170306       0       0   \n",
       "4  Rq9NMOw9RAbN3qUIG1MUU+vL0lqhAJUAsZiW0dsm/Lg=  20170322       9       7   \n",
       "\n",
       "   num_75  num_985  num_100  num_unq  total_secs  \n",
       "0       0        1       25       26    6306.242  \n",
       "1       2        3       36       34   10718.255  \n",
       "2       0        0       21       21    4948.548  \n",
       "3       1        0       28        1    3436.411  \n",
       "4       4        2       48       67   13534.787  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/logs.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0980ec4-64eb-4e1c-9c70-00a6af9a0076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "390000000.0 rows processed.\n",
      "Overall time: 969 seconds.\n"
     ]
    }
   ],
   "source": [
    "chunksize = 1e7\n",
    "\n",
    "start = timer()\n",
    "\n",
    "for i, chunk in enumerate(pd.read_csv('/Users/dususu/Desktop/kkbox-churn-prediction-challenge/user_logs.csv', chunksize = chunksize)):\n",
    "    partition_by_hashing(chunk, name = 'logs', progress = None)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f'{i * chunksize} rows processed.', end = '\\r')\n",
    "    \n",
    "end = timer()\n",
    "print(f'\\nOverall time: {round(end - start)} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf5492a7-0e56-4aa6-a741-551d99ebd711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>msno</th>\n",
       "      <th>date</th>\n",
       "      <th>num_25</th>\n",
       "      <th>num_50</th>\n",
       "      <th>num_75</th>\n",
       "      <th>num_985</th>\n",
       "      <th>num_100</th>\n",
       "      <th>num_unq</th>\n",
       "      <th>total_secs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402013</th>\n",
       "      <td>fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=</td>\n",
       "      <td>20160509</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4187.548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402014</th>\n",
       "      <td>fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=</td>\n",
       "      <td>20160703</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>924.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402015</th>\n",
       "      <td>fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=</td>\n",
       "      <td>20161004</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>6031.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402016</th>\n",
       "      <td>fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=</td>\n",
       "      <td>20170101</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>790.686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402017</th>\n",
       "      <td>xVJ8UUCOfXv5dXwxjFP5ffOHP+kgRRZbM7Mf5hJe0AE=</td>\n",
       "      <td>20150126</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>321.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                msno      date  num_25  \\\n",
       "402013  fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=  20160509       0   \n",
       "402014  fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=  20160703       1   \n",
       "402015  fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=  20161004       2   \n",
       "402016  fBNdslCoBSVgRLCTT/1wz2u5BJE0D4TuF+8g0+IPOLQ=  20170101       0   \n",
       "402017  xVJ8UUCOfXv5dXwxjFP5ffOHP+kgRRZbM7Mf5hJe0AE=  20150126       2   \n",
       "\n",
       "        num_50  num_75  num_985  num_100  num_unq  total_secs  \n",
       "402013       0       0        0       15       15    4187.548  \n",
       "402014       0       0        0        4        4     924.083  \n",
       "402015       0       0        0       24       26    6031.879  \n",
       "402016       3       2        0        1        5     790.686  \n",
       "402017       0       0        0        1        3     321.985  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(base_dir + f'p{partition}/logs.csv').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49e12f8-87d3-4f32-ac23-048c8b6e0e88",
   "metadata": {},
   "source": [
    "### 结论\n",
    "\n",
    "在这个 Notebook 中，我们实现了一个数据集的分区，该数据集通常太大而无法放入内存。在尝试了几种选择后，我们最终决定了最快的方法，即：\n",
    "\n",
    "使用哈希函数将客户 ID 映射到分区。\n",
    "\n",
    "计算整数哈希值，然后除以分区数。\n",
    "\n",
    "按分区对 DataFrame 进行分组，并将每个分区写入相应的目录和文件。\n",
    "\n",
    "对于无法完全放入内存的大文件，通过分块读取，并将每个数据块发送到分区函数。\n",
    "\n",
    "现在我们可以在单个分区上开发一个自动化的特征工程管道。 在管道开发完成后，我们可以使用 Spark 或 Dask 等框架并行运行管道中的分区。这将加快整体的特征工程过程，并允许我们扩展到更大的数据集。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0a91e-ba32-4860-a56e-2b30115fe2ab",
   "metadata": {},
   "source": [
    "### 下一步\n",
    "\n",
    "为了实现机器学习解决方案，我们需要采取以下流程中概述的几个步骤：\n",
    "\n",
    "预测工程： 定义业务需求，并将其转化为机器学习问题。创建一组有标签的历史示例（称为标签时间），这些示例可以用于为每个标签构建特征。\n",
    "\n",
    "使用标签时间来构建每个标签的特征： 通过过滤截至截止时间之前的数据。这个过程可以使用自动化特征工程快速完成。\n",
    "\n",
    "训练一个机器学习算法： 从这些特征预测标签。一旦模型优化完成，就使用它来对新数据进行预测。\n",
    "\n",
    "由于数据已被分区，前两步可以并行快速完成。第一步在“预测工程”Notebook 中实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcab73f5-44c6-4d12-8b5f-360a741a7bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899bdcb9-a528-4a04-b2ad-3d832f634b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a75b8dd-b22d-4d1a-87aa-7a75976d3dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52c1b1d-b2db-4c74-be2b-c7a81ee76682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e714f-8476-463c-8f81-e6bb811f3ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71bc06-a124-4fc6-a50c-dade54824c73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25baa45f-509a-434d-8ca1-416f618bc127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4b5cd2-c34b-4c87-a93f-717491600343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727ec26-1c80-4f48-b954-d178a337251c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46223ea8-37df-4b77-8608-b2eaceb964b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e28e7-b41d-4d23-ba71-0b472029d3e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f4d8cb-f947-4cdf-a746-f2a10e24d962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
